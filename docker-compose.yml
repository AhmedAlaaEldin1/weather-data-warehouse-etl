version: "3.8"

services:
  postgres:
    image: postgres:15
    container_name: de_postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - ./postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - dataeng_net

  minio:
    image: minio/minio:latest
    container_name: de_minio
    restart: unless-stopped
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    command: server /data --console-address ":9001"
    volumes:
      - ./minio_data:/data
    ports:
      - "9000:9000"
      - "9001:9001"
    networks:
      - dataeng_net

  # ✅ Apache Spark (الصورة الرسمية)
  spark-master:
    build:
      context: .
      dockerfile: Dockerfile.spark
    container_name: spark-master
    command: >
      bash -c "/opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
      --host spark-master --port 7077 --webui-port 8082"
    ports:
      - "7077:7077"
      - "8082:8082"
    networks:
      - dataeng_net

  spark-worker:
    build:
      context: .
      dockerfile: Dockerfile.spark
    container_name: spark-worker
    depends_on:
      - spark-master
    command: >
      bash -c "/opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker
      spark://spark-master:7077 --webui-port 8083"
    ports:
      - "8083:8083"
    networks:
      - dataeng_net

  jupyter:
    image: jupyter/pyspark-notebook:latest
    container_name: de_jupyter
    restart: unless-stopped
    volumes:
      - ./notebooks:/home/jovyan/work
      - ./project:/home/jovyan/work/project
    ports:
      - "8888:8888"
    environment:
      SPARK_MASTER: spark://spark-master:7077
    depends_on:
      - spark-master
    networks:
      - dataeng_net

  airflow-init:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    container_name: de_airflow_init
    restart: "no"
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: "LocalExecutor"
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: "postgresql+psycopg2://airflow:airflow@postgres:5432/airflow"
      AIRFLOW__CORE__FERNET_KEY: "vyrXDDhvYEjqdCqRBL6Q16sV8L4aDKGywYAKZ8lm634="
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
      AIRFLOW__WEBSERVER__RBAC: "True"
      AIRFLOW_UID: "50000"
    volumes:
      - ./airflow/data:/opt/airflow/data
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
    entrypoint: >
      bash -c "airflow db upgrade && \
               airflow users create --username admin --firstname Admin --lastname User --role Admin --email admin@example.com --password admin || true"
    networks:
      - dataeng_net
    
  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    container_name: de_airflow_web
    restart: unless-stopped
    depends_on:
      - airflow-init
    environment:
      AIRFLOW__CORE__EXECUTOR: "LocalExecutor"
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: "postgresql+psycopg2://airflow:airflow@postgres:5432/airflow"
      AIRFLOW__CORE__FERNET_KEY: "vyrXDDhvYEjqdCqRBL6Q16sV8L4aDKGywYAKZ8lm634="
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
      AIRFLOW__WEBSERVER__RBAC: "True"
      AIRFLOW_UID: "50000"
    volumes:
      - ./airflow/data:/opt/airflow/data
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
    ports:
      - "8081:8080"
    command: webserver
    networks:
      - dataeng_net


  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile.airflow
    container_name: de_airflow_scheduler
    restart: unless-stopped
    depends_on:
      - airflow-webserver
    environment:
      AIRFLOW__CORE__EXECUTOR: "LocalExecutor"
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: "postgresql+psycopg2://airflow:airflow@postgres:5432/airflow"
      AIRFLOW__CORE__FERNET_KEY: "vyrXDDhvYEjqdCqRBL6Q16sV8L4aDKGywYAKZ8lm634="
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
      AIRFLOW__WEBSERVER__RBAC: "True"
      AIRFLOW_UID: "50000"
    volumes:
      - ./airflow/data:/opt/airflow/data
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
    command: scheduler
    networks:
      - dataeng_net
      
networks:
  dataeng_net:
    external:
      name: dataengineering_dataeng_net
